{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448,
          "referenced_widgets": [
            "c903b6d555674eb884b463d78387c3cd",
            "a7f10c76b99d461587b4ff1073fd9f2e",
            "6a420a2890d24b4787b450a9c6d4471b",
            "160c7067c3d04a43bfbdd9b0fd286008",
            "533213c95c56450db059468d5304e1c4",
            "5276eba0e63a4da688116b8c78fe7bc8",
            "ad1cb310b96f41b3b5f50afdd5966440",
            "16a72f61aee04b779a85d0d877d2c5aa",
            "d1981e5ab3744f989d4a536a052bb22d",
            "ddf3dd8a5dff4c529051c2a6a277e724",
            "afff49cd9afa4fac90a125139be0a742",
            "7db8e0ea599a43c88a558f4a2f3f6119",
            "675dac761a344ac59f8856e339166e69",
            "323d0213ef1c499a9118b4e4a22cd3bc",
            "55a7dcbf98c34cd783af82da8211748b",
            "868e83ebe3cd4f2eb5573410e8a3fc8f",
            "a42751ea91d64883b75dcca5f84ab496",
            "cd1eefdc63bc431681ea25bdb23b15a1",
            "ea6c765581e3498aae479983d4b83fb8",
            "69812d34f7484d058477476b6fa2d266",
            "753897ef76d94f8185b909d22e4aa50d",
            "5bcb4fb0f99b41fc8839168cef6a5171"
          ]
        },
        "id": "s38YmdTk-1Dn",
        "outputId": "be7d8e53-4755-4079-e1f5-4368f17fa209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üìÅ Output folder ready: /content/VISIONFLUX/\n",
            "\n",
            "üîç Checking GPU...\n",
            "‚ö° GPU: Tesla T4\n",
            "üíæ Memory: 15.8 GB\n",
            "\n",
            "üì¶ Model found in Google Drive ‚Äî loading instantly!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c903b6d555674eb884b463d78387c3cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ SDXL-Turbo loaded successfully!\n",
            "üí° Best settings: 1‚Äì4 steps, guidance_scale=0\n",
            "üí° Recommended resolutions: 512 or 1024\n",
            "üé® Generating test image...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7db8e0ea599a43c88a558f4a2f3f6119"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî• Test image generated & saved at: /content/VISIONFLUX/test_output.png\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# 1Ô∏è‚É£ Install Dependencies\n",
        "# ============================================\n",
        "!pip install -q diffusers transformers accelerate safetensors\n",
        "\n",
        "# ============================================\n",
        "# 2Ô∏è‚É£ Mount Google Drive for Persistent Storage\n",
        "# ============================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "\n",
        "# ============================================\n",
        "# 3Ô∏è‚É£ Set Model Name + Permanent Cache Location\n",
        "# ============================================\n",
        "MODEL_NAME = \"stabilityai/sdxl-turbo\"\n",
        "MODEL_CACHE = \"/content/drive/MyDrive/sdxl_turbo_cache/\"\n",
        "os.makedirs(MODEL_CACHE, exist_ok=True)\n",
        "\n",
        "# ============================================\n",
        "# 4Ô∏è‚É£ Create VISIONFLUX folder inside /content\n",
        "# ============================================\n",
        "OUTPUT_DIR = \"/content/VISIONFLUX/\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"üìÅ Output folder ready: {OUTPUT_DIR}\")\n",
        "\n",
        "# ============================================\n",
        "# 5Ô∏è‚É£ Check GPU\n",
        "# ============================================\n",
        "print(\"\\nüîç Checking GPU...\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚ö° GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\\n\")\n",
        "else:\n",
        "    print(\"‚ùå No GPU found! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
        "\n",
        "# ============================================\n",
        "# 6Ô∏è‚É£ Function: Check if Model Already Exists\n",
        "# ============================================\n",
        "def model_exists(cache_dir):\n",
        "    for root, dirs, files in os.walk(cache_dir):\n",
        "        for f in files:\n",
        "            if f.endswith(\".safetensors\") or f.endswith(\".bin\"):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "# ============================================\n",
        "# 7Ô∏è‚É£ Load SDXL Turbo (Skip Download if Already Stored)\n",
        "# ============================================\n",
        "if model_exists(MODEL_CACHE):\n",
        "    print(\"üì¶ Model found in Google Drive ‚Äî loading instantly!\")\n",
        "else:\n",
        "    print(\"‚¨áÔ∏è First-time model download ‚Äî this may take a few minutes...\")\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    cache_dir=MODEL_CACHE\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Enable optimizations\n",
        "pipe.enable_vae_slicing()\n",
        "pipe.enable_attention_slicing()\n",
        "\n",
        "print(\"‚úÖ SDXL-Turbo loaded successfully!\")\n",
        "print(\"üí° Best settings: 1‚Äì4 steps, guidance_scale=0\")\n",
        "print(\"üí° Recommended resolutions: 512 or 1024\")\n",
        "\n",
        "# ============================================\n",
        "# 8Ô∏è‚É£ Quick Test Image\n",
        "# ============================================\n",
        "prompt = \"a beautiful sunset over mountains\"\n",
        "\n",
        "print(\"üé® Generating test image...\")\n",
        "test_image = pipe(\n",
        "    prompt,\n",
        "    num_inference_steps=4,\n",
        "    guidance_scale=0.0\n",
        ").images[0]\n",
        "\n",
        "# üëâ Save inside /content/VISIONFLUX/\n",
        "save_path = os.path.join(OUTPUT_DIR, \"test_output.png\")\n",
        "test_image.save(save_path)\n",
        "\n",
        "test_image.show()\n",
        "\n",
        "print(f\"üî• Test image generated & saved at: {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdtRfAlc_B0w",
        "outputId": "5ad86f5a-c86e-4eb5-d8a5-2587f9dc54a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latents prepared: torch.Size([1, 4, 64, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1879810022.py:3: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  (1, pipe.unet.in_channels, 64, 64),\n"
          ]
        }
      ],
      "source": [
        "# prepare consistent latent noise\n",
        "latents = torch.randn(\n",
        "    (1, pipe.unet.in_channels, 64, 64),\n",
        "    device=pipe.device,\n",
        "    dtype=pipe.dtype\n",
        ")\n",
        "print(\"Latents prepared:\", latents.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qsvxQ7t_EDZ",
        "outputId": "370fdf09-1f72-4f26-fbae-aa9f4e2e2892"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StableDiffusionXLPipeline {\n",
              "  \"_class_name\": \"StableDiffusionXLPipeline\",\n",
              "  \"_diffusers_version\": \"0.35.2\",\n",
              "  \"_name_or_path\": \"stabilityai/sdxl-turbo\",\n",
              "  \"feature_extractor\": [\n",
              "    null,\n",
              "    null\n",
              "  ],\n",
              "  \"force_zeros_for_empty_prompt\": true,\n",
              "  \"image_encoder\": [\n",
              "    null,\n",
              "    null\n",
              "  ],\n",
              "  \"scheduler\": [\n",
              "    \"diffusers\",\n",
              "    \"EulerAncestralDiscreteScheduler\"\n",
              "  ],\n",
              "  \"text_encoder\": [\n",
              "    \"transformers\",\n",
              "    \"CLIPTextModel\"\n",
              "  ],\n",
              "  \"text_encoder_2\": [\n",
              "    \"transformers\",\n",
              "    \"CLIPTextModelWithProjection\"\n",
              "  ],\n",
              "  \"tokenizer\": [\n",
              "    \"transformers\",\n",
              "    \"CLIPTokenizer\"\n",
              "  ],\n",
              "  \"tokenizer_2\": [\n",
              "    \"transformers\",\n",
              "    \"CLIPTokenizer\"\n",
              "  ],\n",
              "  \"unet\": [\n",
              "    \"diffusers\",\n",
              "    \"UNet2DConditionModel\"\n",
              "  ],\n",
              "  \"vae\": [\n",
              "    \"diffusers\",\n",
              "    \"AutoencoderKL\"\n",
              "  ]\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMv94WJs_GMx",
        "outputId": "aac92e5f-7b30-4f10-a6fb-cf22108f0dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-214164105.py:6: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  (1, pipe.unet.in_channels, 64, 64),\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# prepare consistent latent noise\n",
        "latents = torch.randn(\n",
        "    (1, pipe.unet.in_channels, 64, 64),\n",
        "    device=pipe.device,\n",
        "    dtype=pipe.dtype\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kvNmLzn_L9k",
        "outputId": "feb5dded-cb7c-4eb4-cc5b-5de116149ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ECCV2022-RIFE' already exists and is not an empty directory.\n",
            "/content/ECCV2022-RIFE\n",
            "Collecting numpy<=1.23.5,>=1.16 (from -r requirements.txt (line 1))\n",
            "  Using cached numpy-1.23.5.tar.gz (10.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/megvii-research/ECCV2022-RIFE\n",
        "%cd ECCV2022-RIFE\n",
        "\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQNrIgc1_L2T",
        "outputId": "85cfe88a-daaf-49bd-a291-ec75a7ea0ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ECCV2022-RIFE' already exists and is not an empty directory.\n",
            "/content/ECCV2022-RIFE/ECCV2022-RIFE\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hzwer/ECCV2022-RIFE\n",
        "%cd ECCV2022-RIFE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU5A330T_Ooy",
        "outputId": "ca42b2b7-2ba9-4555-a462-acd09c79348d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-01 09:33:09--  https://huggingface.co/hzwer/RIFE/resolve/main/RIFEv4.26_0921.zip\n",
            "Resolving huggingface.co (huggingface.co)... 3.171.171.128, 3.171.171.104, 3.171.171.6, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.171.171.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/6865eed25bb245cdb421bdf7/015d11b9b16e81d9f179fcdb12edd4ef9b10fce1e823214bddd38aa2ddef9095?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251201T093309Z&X-Amz-Expires=3600&X-Amz-Signature=78768b4d1a407ead41cf72867b8fa18b2f754f531ed0444dc3627a56d113a0bd&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27RIFEv4.26_0921.zip%3B+filename%3D%22RIFEv4.26_0921.zip%22%3B&response-content-type=application%2Fzip&x-id=GetObject&Expires=1764585189&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDU4NTE4OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODY1ZWVkMjViYjI0NWNkYjQyMWJkZjcvMDE1ZDExYjliMTZlODFkOWYxNzlmY2RiMTJlZGQ0ZWY5YjEwZmNlMWU4MjMyMTRiZGRkMzhhYTJkZGVmOTA5NSoifV19&Signature=p1K0ksT5ePcki--gj5wHn%7EwB%7ElmucuMNicFxWUBnMv0c4jgJm1Qgk1PY%7EueOPbb2NRL5z4vNaNiv4s0Qq9vFTT07S%7EJvYzcbypx2TJXpPzTAHjG5dbg4TPmwIYHFmeqwYwD7vjYTU9GhkQ738-GagkXDYmmtiINO6hLpVaYRzuBcvrkfdZoLU9eIOjn6yTgD%7EONJlAxG%7EuFQ6LAy25eI2CdFoNR0oQH-f3zVw7uzcjDfyr7tRXHSoS6V%7EwBWVYshNQUz-BT-BrBvSsCr7PrVDNaa%7E%7EuzJK-TERbexqnwPkJgQ-TUya36PLk5iZwmgpwuUClJwWTw5m%7EgB6XxBrHN8g__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-12-01 09:33:09--  https://cas-bridge.xethub.hf.co/xet-bridge-us/6865eed25bb245cdb421bdf7/015d11b9b16e81d9f179fcdb12edd4ef9b10fce1e823214bddd38aa2ddef9095?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251201T093309Z&X-Amz-Expires=3600&X-Amz-Signature=78768b4d1a407ead41cf72867b8fa18b2f754f531ed0444dc3627a56d113a0bd&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27RIFEv4.26_0921.zip%3B+filename%3D%22RIFEv4.26_0921.zip%22%3B&response-content-type=application%2Fzip&x-id=GetObject&Expires=1764585189&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDU4NTE4OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODY1ZWVkMjViYjI0NWNkYjQyMWJkZjcvMDE1ZDExYjliMTZlODFkOWYxNzlmY2RiMTJlZGQ0ZWY5YjEwZmNlMWU4MjMyMTRiZGRkMzhhYTJkZGVmOTA5NSoifV19&Signature=p1K0ksT5ePcki--gj5wHn%7EwB%7ElmucuMNicFxWUBnMv0c4jgJm1Qgk1PY%7EueOPbb2NRL5z4vNaNiv4s0Qq9vFTT07S%7EJvYzcbypx2TJXpPzTAHjG5dbg4TPmwIYHFmeqwYwD7vjYTU9GhkQ738-GagkXDYmmtiINO6hLpVaYRzuBcvrkfdZoLU9eIOjn6yTgD%7EONJlAxG%7EuFQ6LAy25eI2CdFoNR0oQH-f3zVw7uzcjDfyr7tRXHSoS6V%7EwBWVYshNQUz-BT-BrBvSsCr7PrVDNaa%7E%7EuzJK-TERbexqnwPkJgQ-TUya36PLk5iZwmgpwuUClJwWTw5m%7EgB6XxBrHN8g__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 13.32.179.6, 13.32.179.58, 13.32.179.62, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|13.32.179.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22869906 (22M) [application/zip]\n",
            "Saving to: ‚ÄòRIFEv4.26_0921.zip‚Äô\n",
            "\n",
            "RIFEv4.26_0921.zip  100%[===================>]  21.81M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-01 09:33:09 (171 MB/s) - ‚ÄòRIFEv4.26_0921.zip‚Äô saved [22869906/22869906]\n",
            "\n",
            "Archive:  RIFEv4.26_0921.zip\n",
            "replace RIFE_model/__MACOSX/._RIFEv4.26_0921? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/__MACOSX/._RIFEv4.26_0921  \n",
            "replace RIFE_model/RIFEv4.26_0921/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/RIFEv4.26_0921/.DS_Store  \n",
            "replace RIFE_model/__MACOSX/RIFEv4.26_0921/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/__MACOSX/RIFEv4.26_0921/._.DS_Store  \n",
            "replace RIFE_model/RIFEv4.26_0921/flownet.pkl? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/RIFEv4.26_0921/flownet.pkl  \n",
            "replace RIFE_model/__MACOSX/RIFEv4.26_0921/._flownet.pkl? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/__MACOSX/RIFEv4.26_0921/._flownet.pkl  \n",
            "replace RIFE_model/RIFEv4.26_0921/IFNet_HDv3.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/RIFEv4.26_0921/IFNet_HDv3.py  \n",
            "replace RIFE_model/__MACOSX/RIFEv4.26_0921/._IFNet_HDv3.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/__MACOSX/RIFEv4.26_0921/._IFNet_HDv3.py  \n",
            "replace RIFE_model/RIFEv4.26_0921/refine.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/RIFEv4.26_0921/refine.py  \n",
            "replace RIFE_model/__MACOSX/RIFEv4.26_0921/._refine.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/__MACOSX/RIFEv4.26_0921/._refine.py  \n",
            "replace RIFE_model/__MACOSX/RIFEv4.26_0921/.___pycache__? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/__MACOSX/RIFEv4.26_0921/.___pycache__  \n",
            "replace RIFE_model/RIFEv4.26_0921/RIFE_HDv3.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/RIFEv4.26_0921/RIFE_HDv3.py  \n",
            "replace RIFE_model/__MACOSX/RIFEv4.26_0921/._RIFE_HDv3.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/__MACOSX/RIFEv4.26_0921/._RIFE_HDv3.py  \n",
            "replace RIFE_model/RIFEv4.26_0921/__pycache__/RIFE_HDv3.cpython-311.pyc? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/RIFEv4.26_0921/__pycache__/RIFE_HDv3.cpython-311.pyc  \n",
            "replace RIFE_model/__MACOSX/RIFEv4.26_0921/__pycache__/._RIFE_HDv3.cpython-311.pyc? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/__MACOSX/RIFEv4.26_0921/__pycache__/._RIFE_HDv3.cpython-311.pyc  \n",
            "replace RIFE_model/RIFEv4.26_0921/__pycache__/IFNet_HDv3.cpython-311.pyc? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/RIFEv4.26_0921/__pycache__/IFNet_HDv3.cpython-311.pyc  \n",
            "replace RIFE_model/__MACOSX/RIFEv4.26_0921/__pycache__/._IFNet_HDv3.cpython-311.pyc? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: RIFE_model/__MACOSX/RIFEv4.26_0921/__pycache__/._IFNet_HDv3.cpython-311.pyc  \n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/hzwer/RIFE/resolve/main/RIFEv4.26_0921.zip -O RIFEv4.26_0921.zip\n",
        "!unzip RIFEv4.26_0921.zip -d RIFE_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcHO9D5h_Sw5",
        "outputId": "1192e8ac-9987-4648-d1f7-a5deb3718caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__MACOSX  RIFEv4.26_0921\n"
          ]
        }
      ],
      "source": [
        "!ls RIFE_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyHYWaI1_VCz",
        "outputId": "942b4fab-7936-4f09-b674-bca93e8e3059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'RIFEv4.26_0921': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls RIFEv4.26_0921"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvvU55GH_Vpy",
        "outputId": "661409f6-439d-4f15-f8ae-0b0ef35150ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ECCV2022-RIFE/ECCV2022-RIFE\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl6TgSZu_ZjE",
        "outputId": "a3a7dfa4-cf3c-4647-b0c0-30fee9678d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  RIFEv4.26_0921.zip\n",
            "  inflating: RIFE_extracted/__MACOSX/._RIFEv4.26_0921  \n",
            "  inflating: RIFE_extracted/RIFEv4.26_0921/.DS_Store  \n",
            "  inflating: RIFE_extracted/__MACOSX/RIFEv4.26_0921/._.DS_Store  \n",
            "  inflating: RIFE_extracted/RIFEv4.26_0921/flownet.pkl  \n",
            "  inflating: RIFE_extracted/__MACOSX/RIFEv4.26_0921/._flownet.pkl  \n",
            "  inflating: RIFE_extracted/RIFEv4.26_0921/IFNet_HDv3.py  \n",
            "  inflating: RIFE_extracted/__MACOSX/RIFEv4.26_0921/._IFNet_HDv3.py  \n",
            "  inflating: RIFE_extracted/RIFEv4.26_0921/refine.py  \n",
            "  inflating: RIFE_extracted/__MACOSX/RIFEv4.26_0921/._refine.py  \n",
            "  inflating: RIFE_extracted/__MACOSX/RIFEv4.26_0921/.___pycache__  \n",
            "  inflating: RIFE_extracted/RIFEv4.26_0921/RIFE_HDv3.py  \n",
            "  inflating: RIFE_extracted/__MACOSX/RIFEv4.26_0921/._RIFE_HDv3.py  \n",
            "  inflating: RIFE_extracted/RIFEv4.26_0921/__pycache__/RIFE_HDv3.cpython-311.pyc  \n",
            "  inflating: RIFE_extracted/__MACOSX/RIFEv4.26_0921/__pycache__/._RIFE_HDv3.cpython-311.pyc  \n",
            "  inflating: RIFE_extracted/RIFEv4.26_0921/__pycache__/IFNet_HDv3.cpython-311.pyc  \n",
            "  inflating: RIFE_extracted/__MACOSX/RIFEv4.26_0921/__pycache__/._IFNet_HDv3.cpython-311.pyc  \n"
          ]
        }
      ],
      "source": [
        "!unzip -o RIFEv4.26_0921.zip -d RIFE_extracted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSRri5_V_bWk",
        "outputId": "3196d1fa-20d4-4f81-bddc-89de87e0dd73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__MACOSX  RIFEv4.26_0921\n"
          ]
        }
      ],
      "source": [
        "!ls RIFE_extracted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a0iKCqxx_dld"
      },
      "outputs": [],
      "source": [
        "!mkdir -p train_log\n",
        "!cp /content/ECCV2022-RIFE/ECCV2022-RIFE/RIFE_extracted/RIFEv4.26_0921/flownet.pkl train_log/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0NtZJjnE_fT8"
      },
      "outputs": [],
      "source": [
        "!cp /content/ECCV2022-RIFE/ECCV2022-RIFE/RIFE_extracted/RIFEv4.26_0921/flownet.pkl train_log/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDjG9WVu_g_k",
        "outputId": "81223550-9be1-4dbe-e7ef-7bf0bd83925a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch opencv-python numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qMdiXdn_hcV",
        "outputId": "edd991af-87b4-4c84-819f-f08c866c309d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.12/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from scikit-video) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from scikit-video) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from scikit-video) (1.16.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfE4sRpl_mDt",
        "outputId": "66f3e17e-eb27-4007-99ba-496b32de9739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied /content/ECCV2022-RIFE/ECCV2022-RIFE/RIFE_extracted/RIFEv4.26_0921/RIFE_HDv3.py to /content/ECCV2022-RIFE/ECCV2022-RIFE/train_log/RIFE_HDv3.py\n",
            "Copied /content/ECCV2022-RIFE/ECCV2022-RIFE/RIFE_extracted/RIFEv4.26_0921/IFNet_HDv3.py to /content/ECCV2022-RIFE/ECCV2022-RIFE/train_log/IFNet_HDv3.py\n",
            "Modified /content/ECCV2022-RIFE/ECCV2022-RIFE/model/RIFE.py to include map_location='cpu'.\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "import shutil # Import shutil for copying files\n",
        "\n",
        "\n",
        "# Path to the RIFE.py file that needs modification\n",
        "rife_file_path = \"/content/ECCV2022-RIFE/ECCV2022-RIFE/model/RIFE.py\"\n",
        "rife_hd_v3_source_path = \"/content/ECCV2022-RIFE/ECCV2022-RIFE/RIFE_extracted/RIFEv4.26_0921/RIFE_HDv3.py\"\n",
        "ifnet_hd_v3_source_path = \"/content/ECCV2022-RIFE/ECCV2022-RIFE/RIFE_extracted/RIFEv4.26_0921/IFNet_HDv3.py\"\n",
        "\n",
        "train_log_dir = \"/content/ECCV2022-RIFE/ECCV2022-RIFE/train_log\"\n",
        "rife_hd_v3_dest_path = os.path.join(train_log_dir, \"RIFE_HDv3.py\")\n",
        "ifnet_hd_v3_dest_path = os.path.join(train_log_dir, \"IFNet_HDv3.py\")\n",
        "\n",
        "# Ensure train_log directory exists\n",
        "os.makedirs(train_log_dir, exist_ok=True)\n",
        "\n",
        "# Copy RIFE_HDv3.py to train_log\n",
        "if os.path.exists(rife_hd_v3_source_path):\n",
        "    try:\n",
        "        shutil.copy(rife_hd_v3_source_path, rife_hd_v3_dest_path)\n",
        "        print(f\"Copied {rife_hd_v3_source_path} to {rife_hd_v3_dest_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error copying RIFE_HDv3.py: {e}\")\n",
        "else:\n",
        "    print(f\"Error: RIFE_HDv3.py not found at {rife_hd_v3_source_path}\")\n",
        "\n",
        "# Copy IFNet_HDv3.py to train_log\n",
        "if os.path.exists(ifnet_hd_v3_source_path):\n",
        "    try:\n",
        "        shutil.copy(ifnet_hd_v3_source_path, ifnet_hd_v3_dest_path)\n",
        "        print(f\"Copied {ifnet_hd_v3_source_path} to {ifnet_hd_v3_dest_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error copying IFNet_HDv3.py: {e}\")\n",
        "else:\n",
        "    print(f\"Error: IFNet_HDv3.py not found at {ifnet_hd_v3_source_path}\")\n",
        "\n",
        "\n",
        "# Check if the file exists before attempting to modify\n",
        "if os.path.exists(rife_file_path):\n",
        "    try:\n",
        "        # Perform modification\n",
        "        with fileinput.FileInput(rife_file_path, inplace=True) as file:\n",
        "            for line in file:\n",
        "                # Replace the line that loads the flownet.pkl to include map_location='cpu'\n",
        "                if \"torch.load('{}/flownet.pkl'.format(path))\" in line and \"map_location='cpu'\" not in line:\n",
        "                    print(line.replace(\"torch.load('{}/flownet.pkl'.format(path))\",\n",
        "                                       \"torch.load('{}/flownet.pkl'.format(path), map_location='cpu')\"), end='')\n",
        "                else:\n",
        "                    print(line, end='')\n",
        "        print(f\"Modified {rife_file_path} to include map_location='cpu'.\")\n",
        "\n",
        "        # Remove the modules from sys.modules to force reload\n",
        "        # Ensure all potential RIFE model modules are cleared\n",
        "        for module_name in ['model.RIFE', 'model.RIFE_HD', 'model.RIFE_HDv2', 'model.RIFE_HDv3', 'train_log.RIFE_HDv3', 'train_log.IFNet_HDv3', 'model', 'inference_video']:\n",
        "            if module_name in sys.modules:\n",
        "                del sys.modules[module_name]\n",
        "                print(f\"Removed '{module_name}' from sys.modules to force reload.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error modifying {rife_file_path}: {e}\")\n",
        "else:\n",
        "    print(f\"Error: File not found at {rife_file_path}. Cannot apply map_location fix.\")\n",
        "\n",
        "# Add current directory and train_log to sys.path to ensure modules are found\n",
        "if '/content/ECCV2022-RIFE/ECCV2022-RIFE' not in sys.path:\n",
        "    sys.path.insert(0, '/content/ECCV2022-RIFE/ECCV2022-RIFE')\n",
        "if train_log_dir not in sys.path:\n",
        "    sys.path.insert(0, train_log_dir)\n",
        "\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "# Directly import Model from its definition file now that it's copied and path is set\n",
        "from train_log.RIFE_HDv3 import Model\n",
        "\n",
        "# Determine the device to use (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# load model\n",
        "model = Model()\n",
        "model.load_model(train_log_dir) # Pass train_log_dir as modelDir\n",
        "model.eval()\n",
        "\n",
        "# FIX: The Model class itself doesn't have a .to() method. Its internal 'flownet' does.\n",
        "if hasattr(model, 'flownet') and isinstance(model.flownet, torch.nn.Module):\n",
        "    model.flownet.to(device) # Move the internal network to the selected device\n",
        "else:\n",
        "    print(\"Warning: model.flownet not found or not a torch.nn.Module. Cannot move to device.\")\n",
        "\n",
        "# Since inference_video.py is no longer imported directly to get the Model,\n",
        "# the temporary sys.argv modification is not needed and can be removed.\n",
        "# Restore original sys.argv is also not needed here as we didn't modify it at the start of this final version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "6L1SX4uc_vWv",
        "outputId": "c2c93c96-e310-4267-c1c3-57abe8d83044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.118.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [15847]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üöÄ VisionFlux Server is LIVE!\n",
            "============================================================\n",
            "Public URL: https://picked-danica-dimensionally.ngrok-free.dev\n",
            "============================================================\n",
            "Copy the URL above and paste it into your frontend!\n",
            "============================================================\n",
            "Generating for prompt:  An image of a man sitting in top of mountain\n",
            "Error: name 'pipe' is not defined\n",
            "INFO:     2401:4900:93e8:7c04:94b:b833:7b26:d617:0 - \"POST /generate HTTP/1.1\" 500 Internal Server Error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2908388580.py\", line 64, in generate\n",
            "    (1, pipe.unet.in_channels, 64, 64),\n",
            "        ^^^^\n",
            "NameError: name 'pipe' is not defined\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Event loop stopped before Future completed.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2908388580.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;31m# Run the server's serve method in the existing loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Event loop stopped before Future completed."
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# VISIONFLUX COLAB SERVER SCRIPT\n",
        "# Copy this into a NEW cell in your Google Colab notebook\n",
        "# AFTER you've loaded your models (pipe, RIFE model, etc.)\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "# 1. Install dependencies (if not already installed)\n",
        "!pip install fastapi uvicorn pyngrok nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import torch\n",
        "import base64\n",
        "import io\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import asyncio # Import asyncio\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# ASSUMPTION: You have already loaded these in previous cells:\n",
        "# - pipe: StableDiffusionPipeline (for text-to-image)\n",
        "# - model: RIFE Model (for frame interpolation)\n",
        "# - device: torch.device\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class GenerateRequest(BaseModel):\n",
        "    prompt: str\n",
        "    num_inference_steps: int = 12\n",
        "    num_frames: int = 4  # How many frames to generate\n",
        "    use_interpolation: bool = True  # Whether to use RIFE\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"status\": \"Colab Server Running\", \"message\": \"VisionFlux API Ready\"}\n",
        "\n",
        "@app.post(\"/generate\")\n",
        "def generate(req: GenerateRequest):\n",
        "    \"\"\"\n",
        "    Generates a video from a text prompt using your loaded models.\n",
        "    Returns base64-encoded video or GIF.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"Generating for prompt: {req.prompt}\")\n",
        "\n",
        "        # Create output directory\n",
        "        temp_dir = \"/content/temp_generation\"\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # STEP 1: Generate frames using Stable Diffusion\n",
        "        # ------------------------------------------------------------------\n",
        "        frames = []\n",
        "        base_prompt = req.prompt\n",
        "\n",
        "        # Generate consistent latents for the sequence\n",
        "        latents = torch.randn(\n",
        "            (1, pipe.unet.in_channels, 64, 64),\n",
        "            device=pipe.device,\n",
        "            dtype=pipe.dtype\n",
        "        )\n",
        "\n",
        "        # Generate multiple frames with slight variations\n",
        "        for i in range(req.num_frames):\n",
        "            # Add motion description to prompt\n",
        "            motion_prompts = [\n",
        "                f\"{base_prompt}, starting pose\",\n",
        "                f\"{base_prompt}, slight movement forward\",\n",
        "                f\"{base_prompt}, mid-motion\",\n",
        "                f\"{base_prompt}, ending pose\"\n",
        "            ]\n",
        "\n",
        "            current_prompt = motion_prompts[min(i, len(motion_prompts)-1)]\n",
        "\n",
        "            # Generate image with consistent latents\n",
        "            image = pipe(\n",
        "                current_prompt,\n",
        "                latents=latents,\n",
        "                num_inference_steps=req.num_inference_steps,\n",
        "                guidance_scale=5\n",
        "            ).images[0]\n",
        "\n",
        "            frames.append(image)\n",
        "\n",
        "            # Save frame\n",
        "            frame_path = os.path.join(temp_dir, f\"frame_{i:03d}.png\")\n",
        "            image.save(frame_path)\n",
        "            print(f\"Generated frame {i+1}/{req.num_frames}\")\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # STEP 2: Apply RIFE interpolation (if enabled and model loaded)\n",
        "        # ------------------------------------------------------------------\n",
        "        if req.use_interpolation and 'model' in globals():\n",
        "            print(\"Applying RIFE interpolation...\")\n",
        "            interpolated_frames = []\n",
        "\n",
        "            for i in range(len(frames) - 1):\n",
        "                # Add current frame\n",
        "                interpolated_frames.append(frames[i])\n",
        "\n",
        "                # Interpolate between current and next frame\n",
        "                img1 = cv2.cvtColor(np.array(frames[i]), cv2.COLOR_RGB2BGR)\n",
        "                img2 = cv2.cvtColor(np.array(frames[i+1]), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "                # Convert to tensor\n",
        "                img1_tensor = torch.from_numpy(img1.transpose(2, 0, 1)).unsqueeze(0).float() / 255.\n",
        "                img2_tensor = torch.from_numpy(img2.transpose(2, 0, 1)).unsqueeze(0).float() / 255.\n",
        "\n",
        "                # Move to device\n",
        "                img1_tensor = img1_tensor.to(device)\n",
        "                img2_tensor = img2_tensor.to(device)\n",
        "\n",
        "                # Interpolate\n",
        "                with torch.no_grad():\n",
        "                    mid = model.inference(img1_tensor, img2_tensor)[0]\n",
        "\n",
        "                mid_np = (mid.cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8)\n",
        "                mid_rgb = cv2.cvtColor(mid_np, cv2.COLOR_BGR2RGB)\n",
        "                interpolated_frames.append(Image.fromarray(mid_rgb))\n",
        "\n",
        "            # Add last frame\n",
        "            interpolated_frames.append(frames[-1])\n",
        "            frames = interpolated_frames\n",
        "            print(f\"Interpolation complete. Total frames: {len(frames)}\")\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # STEP 3: Create GIF or return first frame as preview\n",
        "        # ------------------------------------------------------------------\n",
        "        if len(frames) > 1:\n",
        "            # Create animated GIF\n",
        "            gif_path = os.path.join(temp_dir, \"output.gif\")\n",
        "            frames[0].save(\n",
        "                gif_path,\n",
        "                save_all=True,\n",
        "                append_images=frames[1:],\n",
        "                duration=200,  # 200ms per frame = 5 FPS\n",
        "                loop=0\n",
        "            )\n",
        "\n",
        "            # Read and encode GIF\n",
        "            with open(gif_path, \"rb\") as f:\n",
        "                gif_bytes = f.read()\n",
        "\n",
        "            gif_b64 = base64.b64encode(gif_bytes).decode(\"utf-8\")\n",
        "\n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"image_base64\": gif_b64,\n",
        "                \"format\": \"gif\",\n",
        "                \"num_frames\": len(frames),\n",
        "                \"message\": f\"Generated {len(frames)} frames\"\n",
        "            }\n",
        "        else:\n",
        "            # Return single image\n",
        "            buffered = io.BytesIO()\n",
        "            frames[0].save(buffered, format=\"PNG\")\n",
        "            img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"image_base64\": img_str,\n",
        "                \"format\": \"png\",\n",
        "                \"num_frames\": 1\n",
        "            }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Set up ngrok with your auth token\n",
        "# ------------------------------------------------------------------\n",
        "ngrok.set_auth_token(\"36BVGKWdcZOEKNe9yxIl1HiGobL_A6Du4wRsJvbaLkx8Rwoe\")\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('=' * 60)\n",
        "print('üöÄ VisionFlux Server is LIVE!')\n",
        "print('=' * 60)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "print('=' * 60)\n",
        "print('Copy the URL above and paste it into your frontend!')\n",
        "print('=' * 60)\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configure Uvicorn\n",
        "config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, loop=\"asyncio\")\n",
        "server = uvicorn.Server(config)\n",
        "\n",
        "# Get the already running event loop (patched by nest_asyncio)\n",
        "loop = asyncio.get_event_loop()\n",
        "\n",
        "# Run the server's serve method in the existing loop\n",
        "loop.run_until_complete(server.serve())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c903b6d555674eb884b463d78387c3cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7f10c76b99d461587b4ff1073fd9f2e",
              "IPY_MODEL_6a420a2890d24b4787b450a9c6d4471b",
              "IPY_MODEL_160c7067c3d04a43bfbdd9b0fd286008"
            ],
            "layout": "IPY_MODEL_533213c95c56450db059468d5304e1c4"
          }
        },
        "a7f10c76b99d461587b4ff1073fd9f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5276eba0e63a4da688116b8c78fe7bc8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ad1cb310b96f41b3b5f50afdd5966440",
            "value": "Loading‚Äápipeline‚Äácomponents...:‚Äá100%"
          }
        },
        "6a420a2890d24b4787b450a9c6d4471b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a72f61aee04b779a85d0d877d2c5aa",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1981e5ab3744f989d4a536a052bb22d",
            "value": 7
          }
        },
        "160c7067c3d04a43bfbdd9b0fd286008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddf3dd8a5dff4c529051c2a6a277e724",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_afff49cd9afa4fac90a125139be0a742",
            "value": "‚Äá7/7‚Äá[00:05&lt;00:00,‚Äá‚Äá2.28it/s]"
          }
        },
        "533213c95c56450db059468d5304e1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5276eba0e63a4da688116b8c78fe7bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1cb310b96f41b3b5f50afdd5966440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16a72f61aee04b779a85d0d877d2c5aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1981e5ab3744f989d4a536a052bb22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddf3dd8a5dff4c529051c2a6a277e724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afff49cd9afa4fac90a125139be0a742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7db8e0ea599a43c88a558f4a2f3f6119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_675dac761a344ac59f8856e339166e69",
              "IPY_MODEL_323d0213ef1c499a9118b4e4a22cd3bc",
              "IPY_MODEL_55a7dcbf98c34cd783af82da8211748b"
            ],
            "layout": "IPY_MODEL_868e83ebe3cd4f2eb5573410e8a3fc8f"
          }
        },
        "675dac761a344ac59f8856e339166e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a42751ea91d64883b75dcca5f84ab496",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cd1eefdc63bc431681ea25bdb23b15a1",
            "value": "100%"
          }
        },
        "323d0213ef1c499a9118b4e4a22cd3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea6c765581e3498aae479983d4b83fb8",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69812d34f7484d058477476b6fa2d266",
            "value": 4
          }
        },
        "55a7dcbf98c34cd783af82da8211748b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_753897ef76d94f8185b909d22e4aa50d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5bcb4fb0f99b41fc8839168cef6a5171",
            "value": "‚Äá4/4‚Äá[00:01&lt;00:00,‚Äá‚Äá4.03it/s]"
          }
        },
        "868e83ebe3cd4f2eb5573410e8a3fc8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a42751ea91d64883b75dcca5f84ab496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1eefdc63bc431681ea25bdb23b15a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea6c765581e3498aae479983d4b83fb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69812d34f7484d058477476b6fa2d266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "753897ef76d94f8185b909d22e4aa50d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bcb4fb0f99b41fc8839168cef6a5171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}